STAT 545 Class Meeting 10
================

Learning Objectives
===================

#### Resources

Some useful resources for data frame joins: - Jenny's [Cheatsheet](bit001_dplyr-cheatsheet.html) for `dplyr` join functions. - Possibly look at Jenny's [Tidy data using Lord of the Rings](https://github.com/jennybc/lotr-tidy) - "two-table verbs"'s [vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/two-table.html) on For data reshaping: - The `tidyr`'s [vignette](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)

We are going to use a set of datasets that Joey put together for us. You can install them from github.

``` r
# if you have not installed devtools, time to do it (uncomment following line)
# uncomment and run the following line to get the `singer` package
devtools::install_github("JoeyBernhardt/singer")
```

    ## Skipping install of 'singer' from a github remote, the SHA1 (2b4fe9cb) has not changed since last install.
    ##   Use `force = TRUE` to force installation

Join together
-------------

For the first part of the lecture, we are going to work a tad on some more joining operation.

The package `singer` comes with two smallish dataframe about songs and artists. Let's take a look at them

``` r
library(singer)
data("songs")
songs
```

    ## # A tibble: 22 x 3
    ##    title                            artist_name      year
    ##    <chr>                            <chr>           <int>
    ##  1 Corduroy                         Pearl Jam        1994
    ##  2 Grievance                        Pearl Jam        2000
    ##  3 Stupidmop                        Pearl Jam        1994
    ##  4 Present Tense                    Pearl Jam        1996
    ##  5 MFC                              Pearl Jam        1998
    ##  6 Lukin                            Pearl Jam        1996
    ##  7 It's Lulu                        The Boo Radleys  1995
    ##  8 Sparrow                          The Boo Radleys  1992
    ##  9 Martin_ Doom! It's Seven O'Clock The Boo Radleys  1995
    ## 10 Leaves And Sand                  The Boo Radleys  1993
    ## # ... with 12 more rows

``` r
data("locations")
locations
```

    ## # A tibble: 14 x 4
    ##    artist_name   city        release             title                    
    ##    <chr>         <chr>       <chr>               <chr>                    
    ##  1 Pearl Jam     Seattle, WA Binaural            Grievance                
    ##  2 Pearl Jam     Seattle, WA Vitalogy            Stupidmop                
    ##  3 Pearl Jam     Seattle, WA No Code             Present Tense            
    ##  4 Pearl Jam     Seattle, WA Live On Two Legs    MFC                      
    ##  5 Pearl Jam     Seattle, WA Seattle Washington~ Lukin                    
    ##  6 The Boo Radl~ Liverpool,~ Wake Up!            Stuck On Amber           
    ##  7 The Boo Radl~ Liverpool,~ Best Of             It's Lulu                
    ##  8 The Boo Radl~ Liverpool,~ Everything's Alrig~ Sparrow                  
    ##  9 The Boo Radl~ Liverpool,~ Kingsize            High as Monkeys          
    ## 10 The Boo Radl~ Liverpool,~ Giant Steps         Butterfly McQueen        
    ## 11 Carly Simon   New York, ~ Moonlight Serenade  My One and Only Love     
    ## 12 Carly Simon   New York, ~ No Secrets          It Was So Easy  (LP Vers~
    ## 13 Carly Simon   New York, ~ Clouds In My Coffe~ I've Got A Crush On You  
    ## 14 Carly Simon   New York, ~ Into White          "Manha De Carnaval (Them~

### Challenge 1

What flow would you use to get a dataframe with all the rows from `songs` where there is matching information the in `locations` dataframe?

``` r
inner_join(songs, locations)
```

    ## Joining, by = c("title", "artist_name")

    ## # A tibble: 13 x 5
    ##    title                   artist_name    year city      release          
    ##    <chr>                   <chr>         <int> <chr>     <chr>            
    ##  1 Grievance               Pearl Jam      2000 Seattle,~ Binaural         
    ##  2 Stupidmop               Pearl Jam      1994 Seattle,~ Vitalogy         
    ##  3 Present Tense           Pearl Jam      1996 Seattle,~ No Code          
    ##  4 MFC                     Pearl Jam      1998 Seattle,~ Live On Two Legs 
    ##  5 Lukin                   Pearl Jam      1996 Seattle,~ Seattle Washingt~
    ##  6 It's Lulu               The Boo Radl~  1995 Liverpoo~ Best Of          
    ##  7 Sparrow                 The Boo Radl~  1992 Liverpoo~ Everything's Alr~
    ##  8 High as Monkeys         The Boo Radl~  1998 Liverpoo~ Kingsize         
    ##  9 Butterfly McQueen       The Boo Radl~  1993 Liverpoo~ Giant Steps      
    ## 10 My One and Only Love    Carly Simon    2005 New York~ Moonlight Serena~
    ## 11 It Was So Easy  (LP Ve~ Carly Simon    1972 New York~ No Secrets       
    ## 12 I've Got A Crush On You Carly Simon    1994 New York~ Clouds In My Cof~
    ## 13 "Manha De Carnaval (Th~ Carly Simon    2007 New York~ Into White

### Challenge 2

What flow would you use to get a dataframe with all the rows from `songs` where there is matching information the in `locations` dataframe, getting back a dataframe with `title`, `artist_name` and `year`?

``` r
merge(songs, locations, all.x=TRUE)[, c('title', 'artist_name', 'year')]
```

    ##                                             title     artist_name year
    ## 1                                        Babydoll    Mariah Carey 1997
    ## 2                               Butterfly McQueen The Boo Radleys 1993
    ## 3                                  Comb Your Hair The Boo Radleys 1998
    ## 4                                        Corduroy       Pearl Jam 1994
    ## 5                           Don't Forget About Us    Mariah Carey 2005
    ## 6                           Don't Forget About Us    Mariah Carey 2005
    ## 7                                       Grievance       Pearl Jam 2000
    ## 8                                 High as Monkeys The Boo Radleys 1998
    ## 9                         I've Got A Crush On You     Carly Simon 1994
    ## 10                   It Was So Easy  (LP Version)     Carly Simon 1972
    ## 11                                      It's Lulu The Boo Radleys 1995
    ## 12                                Leaves And Sand The Boo Radleys 1993
    ## 13                                          Lukin       Pearl Jam 1996
    ## 14                                            MFC       Pearl Jam 1998
    ## 15 Manha De Carnaval (Theme from "Black Orpheus")     Carly Simon 2007
    ## 16               Martin_ Doom! It's Seven O'Clock The Boo Radleys 1995
    ## 17                                     Mine Again    Mariah Carey 2005
    ## 18                           My One and Only Love     Carly Simon 2005
    ## 19                                  Present Tense       Pearl Jam 1996
    ## 20                                        Sparrow The Boo Radleys 1992
    ## 21                                      Stupidmop       Pearl Jam 1994
    ## 22                                 Vision Of Love    Mariah Carey 1990

### Challenge 2

What command(s) would you use to get a dataframe with all the rows from `songs` where there is matching information the in `locations` dataframe, getting back a dataframe with `title`, `artist_name` and `year`?

### Challenge 3

What flow would you use to get the number of releases (albums) present in this two small datasets per year?

Reshaping
---------

Let's consider the bigger datagrame `artist_locations`

``` r
data("singer_locations")
singer_locations
```

    ## # A tibble: 10,100 x 14
    ##    track_id title song_id release artist_id artist_name  year duration
    ##    <chr>    <chr> <chr>   <chr>   <chr>     <chr>       <int>    <dbl>
    ##  1 TRWICRA~ The ~ SOSURT~ Even I~ ARACDPV1~ Motion Cit~  2007     170.
    ##  2 TRXJANY~ Lone~ SODESQ~ The Du~ ARYBUAO1~ Gene Chand~  2004     107.
    ##  3 TRIKPCA~ Here~ SOQUYQ~ Improm~ AR4111G1~ Paul Horn    1998     528.
    ##  4 TRYEATD~ Rego~ SOEZGR~ Still ~ ARQDZP31~ Ronnie Ear~  1995     695.
    ##  5 TRBYYXH~ Games SOPIOC~ Afro-H~ AR75GYU1~ Dorothy As~  1968     237.
    ##  6 TRKFFKR~ More~ SOHQSP~ Six Ya~ ARCENE01~ Barleyjuice  2006     193.
    ##  7 TRSSNNI~ out ~ SOIHOM~ Eradic~ AR88PFB1~ Vertigo An~  2003     240.
    ##  8 TRXSSXI~ Endl~ SODTXQ~ Sounds~ ARKQW4V1~ Wir Sind H~  2007     223.
    ##  9 TRDKANB~ I Am~ SOCZZE~ Live F~ ARIWB161~ Simon & Ga~  1966     178.
    ## 10 TRJQSXM~ A pe~ SOFJTI~ Save M~ ARP3U2W1~ Rabia Sorda  2006     260.
    ## # ... with 10,090 more rows, and 6 more variables:
    ## #   artist_hotttnesss <dbl>, artist_familiarity <dbl>, latitude <dbl>,
    ## #   longitude <dbl>, name <chr>, city <chr>

Let's suppose that we would like to do some plotting, showing the mean of `artist_hotttnesss`, `artist_familiarity` and `duration` for `year`. Let's select the appropriate part of the dataframe.

``` r
hfd_y <- singer_locations %>%
  select(year, artist_hotttnesss, artist_familiarity, duration)
```

You may have heard that ggplot prefers long dataframes, what does that mean? Let's see with an example. The dataframe we have is **wide**: that means that the observation presents the values of interest on different columns.

``` r
hfd_y
```

    ## # A tibble: 10,100 x 4
    ##     year artist_hotttnesss artist_familiarity duration
    ##    <int>             <dbl>              <dbl>    <dbl>
    ##  1  2007             0.641              0.823     170.
    ##  2  2004             0.394              0.570     107.
    ##  3  1998             0.431              0.504     528.
    ##  4  1995             0.362              0.477     695.
    ##  5  1968             0.411              0.530     237.
    ##  6  2006             0.376              0.541     193.
    ##  7  2003             0.181              0.274     240.
    ##  8  2007             0.474              0.698     223.
    ##  9  1966             0.510              0.796     178.
    ## 10  2006             0.420              0.593     260.
    ## # ... with 10,090 more rows

To have in on a long format, we can use `tidyr`'s function `gather()`. Let's see:

``` r
hfd_y_long <- hfd_y %>%
  gather(key = "measure", value = "Value", artist_hotttnesss:duration)
```

### micro challenge

Observe the number of rows and the first entries: what do you think it happened?

------------------------------------------------------------------------

We can go back to the wide format using `tidyr`'s function `spread()`. Yet, be braced for a problem:

``` r
# hfd_y_long %>%
  # spread(measure, Value)
```

What did go wrong here? As we had more than one song per year, when we made it long we lost some information: we don't know how to reassemble the wide table. Let's try again, but with additional wizardry: remember that if you want to gather and then spread, you need to have in the dataframe some column(s) uniquely identifying each row. In this case `song_id` does the magic.

``` r
hfd_y_unique <- singer_locations %>%
  select(song_id, year, artist_hotttnesss, artist_familiarity, duration)
```

Gather:

``` r
hfd_y_unique_long <- hfd_y_unique %>%
  gather(key = "measure", value = "Value", artist_hotttnesss:duration)
```

and then spread

``` r
hfd_y_unique_long %>%
  spread(measure, Value)
```

    ## # A tibble: 10,100 x 5
    ##    song_id             year artist_familiarity artist_hotttnesss duration
    ##    <chr>              <int>              <dbl>             <dbl>    <dbl>
    ##  1 SOAACEN12A8C13AC90  2005             0.775              0.482     357.
    ##  2 SOAAEOE12A67021AA2  2002             0.590              0.384     213.
    ##  3 SOAAEUS12AB0184906  1990             0.447              0.427     243.
    ##  4 SOAAHHZ12AB0181950  2005             0.0581             0         254.
    ##  5 SOAAIJG12AAA15D821  2008             0.722              0.486     400.
    ##  6 SOAAMSA12AB0185275  2008             0.624              0.437     208.
    ##  7 SOAAPDT12A6D4F9957  2002             0.502              0.342     277.
    ##  8 SOAAQSY12A58A7CBFF  1990             0.522              0.366     220.
    ##  9 SOAARXN12D021B0F39  2007             0.823              0.576     299.
    ## 10 SOAASND12A58A7A70B  2001             0.648              0.431     226.
    ## # ... with 10,090 more rows
